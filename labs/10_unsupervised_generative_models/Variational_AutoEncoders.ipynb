{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto  Encoders\n",
    "\n",
    "- Reference: Adapted from the Keras example\n",
    "- Auto-Encoding Variational Bayes\n",
    "   https://arxiv.org/abs/1312.6114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(0, 18):\n",
    "    plt.subplot(3, 6, i + 1)\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard full-connected VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_standard = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_standard = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epsilon_std = 1.0\n",
    "\n",
    "\n",
    "def make_encoder(original_dim, intermediate_dim, latent_dim):\n",
    "    x = Input(shape=(original_dim,))\n",
    "    hidden = Dense(intermediate_dim, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(hidden)\n",
    "    z_log_var = Dense(latent_dim)(hidden)\n",
    "    return Model(inputs=x, outputs=[z_mean, z_log_var],\n",
    "                name=\"mlp_encoder\")\n",
    "\n",
    "    \n",
    "encoder = make_encoder(original_dim, intermediate_dim, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The VAE stochastic latent variable\n",
    "\n",
    "We use the reparametrization trick to define a random variable z that is conditioned on the input image x as follows:\n",
    "\n",
    "$$ z \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)) $$\n",
    "\n",
    "The reparametrization tricks defines $z$ has follows:\n",
    "\n",
    "$$ z = \\mu_z(x) + \\sigma_z(x) \\cdot \\epsilon$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n",
    "\n",
    "This way the dependency to between $z$ and $x$ is deterministic and differentiable. The randomness of $z$ only stems from $\\epsilon$ only for a given $x$.\n",
    "\n",
    "Note that in practice the output of the encoder network parameterizes $log(\\sigma^2_z(x)$ instead of $\\sigma_z(x)$. Taking the exponential of $log(\\sigma^2_z(x)$ ensures the positivity of the standard deviation from the raw output of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_func(inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "\n",
    "sampling_layer = Lambda(sampling_func, output_shape=(latent_dim,),\n",
    "                        name=\"latent_sampler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoder(latent_dim, intermediate_dim, original_dim):\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    x = Dense(intermediate_dim, activation='relu')(decoder_input)\n",
    "    x = Dense(original_dim, activation='sigmoid')(x)\n",
    "    return Model(decoder_input, x, name=\"mlp_decoder\")\n",
    "\n",
    "\n",
    "decoder = make_decoder(latent_dim, intermediate_dim, original_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the decoder outputs has random weights and output noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = decoder.predict(np.random.normal(size=(1, latent_dim)))\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated image is completely univariate noise: there is no apparent spatial depenedencies between the pixel values. This reflects the lack of prior structure in the randomly initialized fully-connected decoder network. \n",
    "\n",
    "\n",
    "Let's now the plug the encoder and decoder via the stochastic latent variable $z$ to get the full VAE architecture. The loss function is the negative ELBO of the variational inference problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vae(input_shape, encoder, decoder):\n",
    "    # Build de model architecture by assembling the encoder,\n",
    "    # stochastic latent variable and decoder:\n",
    "    x = Input(shape=input_shape, name=\"input\")\n",
    "    z_mean, z_log_var = encoder(x)\n",
    "    z = sampling_layer([z_mean, z_log_var])\n",
    "    x_decoded_mean = decoder(z)\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # Define the VAE loss\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(\n",
    "        K.flatten(x), K.flatten(x_decoded_mean))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    return vae\n",
    "\n",
    "vae = make_vae((original_dim,), encoder, decoder)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train_standard, epochs=50, batch_size=100,\n",
    "        validation_data=(x_test_standard, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save_weights(\"standard_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " vae.load_weights(\"standard_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model has not yet converged even after 50 epochs. Furthermore it's is not overfitting significantly either. We chose a very low value for the latent dimension. It is likely that using the higher dimensional space could lead to a model either to optimize that would better fit the training set.\n",
    "\n",
    "By sampling from the prior distribution and feeding the random vector to the decoder we can effectively sample from the image model trained by the VAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = decoder.predict(np.random.normal(size=(1, latent_dim)))\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated pictures are blurry but capture of the global organization of pixels required to represent samples from the 10 fashion item categories. The spatial structure has been learned and is only present in the decoder weights.\n",
    "\n",
    "Use `Ctrl-Enter` several times to sample from various locations in the 2D latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D plot of the image classes in the latent space\n",
    "\n",
    "We can also use the encoder to set the visualize the distribution of the test set in the 2D latent space of the VAE model. In the following the colors show the true class labels from the test samples.\n",
    "\n",
    "Note that the VAE is an unsupervised model: it did not use any label information during training. However we can observe that the 2D latent space is largely structured around the categories of images used in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_labels = {0:\"T-shirt/top\", 1:\"Trouser\", 2:\"Pullover\", 3:\"Dress\", 4:\"Coat\", \n",
    "                5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "\n",
    "cb.set_ticks(list(id_to_labels.keys()))\n",
    "cb.set_ticklabels(list(id_to_labels.values()))\n",
    "cb.update_ticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_encoded, x_test_encoded_log_var = encoder.predict(x_test_standard, batch_size=100)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test,\n",
    "            cmap=plt.cm.tab10)\n",
    "cb = plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**\n",
    "\n",
    "- One can see that the class labels 5, 7 and 9 are grouped in a cluster of the latent space. Use matplotlib to display some samples from each of those 3 classes and discover why they have been grouped together by the VAE model.\n",
    "\n",
    "- Similarly: can you qualitatively explain with matplotlib why class 0, 4 and 6 seem to be hard to disentangle in this 2D latent space discovered by the VAE model?\n",
    "\n",
    "- One can observe that the global 2D shape of the encoded dataset is approximately spherical with values with a maximum radius of size 3. Where can you explain where the shape of this marginal latent distribution come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutions/class_5_7_9.py\n",
    "for i in [5, 7, 9]:\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for j in range(5):\n",
    "        plt.subplot(1, 5, j + 1)\n",
    "        plt.imshow(x_train[y_train == i][j], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(\"Samples from class %d:\" % i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutions/class_5_7_9.py\n",
    "for i in [0, 4, 6]:\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for j in range(5):\n",
    "        plt.subplot(1, 5, j + 1)\n",
    "        plt.imshow(x_train[y_train == i][j], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(\"Samples from class %d:\" % i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutions/shape_marginal_latent_distribution.py\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "\n",
    "# Sample from the latent variable prior\n",
    "normal_data = np.random.normal(size=(x_train.shape[0], 2))\n",
    "ax0.scatter(normal_data[:, 0], normal_data[:, 1], alpha=0.1)\n",
    "ax0.set_title(\"Samples from the latent prior $p(z)$\")\n",
    "ax0.set_xlim(-4, 4)\n",
    "ax0.set_ylim(-4, 4)\n",
    "\n",
    "# Sample a z_i from the conditional posterior for each x_i in the test set:\n",
    "z = np.vstack([\n",
    "    np.random.multivariate_normal(\n",
    "        x_test_encoded[i], np.diag(np.exp(x_test_encoded_log_var[i] / 2)))\n",
    "    for i in range(x_test_encoded.shape[0])])\n",
    "ax1.scatter(z[:, 0], z[:, 1], alpha=0.1)\n",
    "ax1.set_title(\"Test samples sampled from the posterior\")\n",
    "ax1.set_xlim(-4, 4)\n",
    "ax1.set_ylim(-4, 4)\n",
    "\n",
    "# Posterior mean value for each sample x_i from the test set:\n",
    "ax2.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], alpha=0.1)\n",
    "ax2.set_title(\"Test samples encoded in latent space\")\n",
    "ax2.set_xlim(-4, 4)\n",
    "ax2.set_ylim(-4, 4);\n",
    "\n",
    "# Analysis:\n",
    "#\n",
    "# The VAE KL divergence term of the Evidence Lower Bound Objective function\n",
    "# is trying force the encoder to match the posterior distribution with the\n",
    "# prior of the latent variable. In our case we used:\n",
    "#               Normal(mean=[0, 0], std=diag([1, 1])\n",
    "# as the prior distribution which means that 99.7% of the points are expected\n",
    "# to lie within a radius of 3 around the origin of the 2D latent plan.\n",
    "#\n",
    "# Selecting different location and scale parameters for the prior (or even\n",
    "# a different distribution such as the uniform distribution) would change the\n",
    "# shape of the encoded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D panel view of samples from the VAE manifold\n",
    "\n",
    "The following linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian to produce values of the latent variables z. This makes it possible to use a square arangement of panels that spans the gaussian prior of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_conv = np.expand_dims(x_train, -1)\n",
    "x_test_conv = np.expand_dims(x_test, -1)\n",
    "x_train_conv.shape, x_test_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "img_rows, img_cols, img_chns = 28, 28, 1\n",
    "filters = 32\n",
    "kernel_size = 3\n",
    "intermediate_dim = 128\n",
    "\n",
    "\n",
    "def make_conv_encoder(img_rows, img_cols, img_chns,\n",
    "                      latent_dim, intermediate_dim):\n",
    "    x = Input(shape=(img_rows, img_cols, img_chns))\n",
    "    x_conv = Conv2D(filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same', activation='relu')(x)\n",
    "    x_conv = BatchNormalization()(x_conv)\n",
    "    x_conv = Conv2D(filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same', activation='relu',\n",
    "                    strides=(2, 2))(x_conv)\n",
    "    x_conv = BatchNormalization()(x_conv)\n",
    "    x_conv = Conv2D(filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same', activation='relu')(x_conv)\n",
    "    x_conv = BatchNormalization()(x_conv)\n",
    "    x_conv = Conv2D(filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same', activation='relu',\n",
    "                    strides=(2, 2))(x_conv)\n",
    "    flat = Flatten()(x_conv)\n",
    "    hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "    z_mean = Dense(latent_dim)(hidden)\n",
    "    z_log_var = Dense(latent_dim)(hidden)\n",
    "    return Model(inputs=x, outputs=[z_mean, z_log_var],\n",
    "                 name='convolutional_encoder')\n",
    "\n",
    "\n",
    "conv_encoder = make_conv_encoder(img_rows, img_cols, img_chns,\n",
    "                                 latent_dim, intermediate_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stochastic latent variable is the same as for the fully-connected model.\n",
    "\n",
    "## Decoder\n",
    "\n",
    "The decoder is also convolutional but instead of downsampling the spatial dimensions from (28, 28) to 2 latent dimensions, it starts from the latent space to upsample a (28, 28) dimensions using strided `Conv2DTranspose` layers.\n",
    "\n",
    "Here again BatchNormalization layers are inserted after the convolution to make optimization converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conv_decoder(latent_dim, intermediate_dim, original_dim,\n",
    "                      spatial_size=7, filters=16):\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    x = Dense(intermediate_dim, activation='relu')(decoder_input)\n",
    "    x = Dense(filters * spatial_size * spatial_size, activation='relu')(x)\n",
    "    x = Reshape((spatial_size, spatial_size, filters))(x)\n",
    "    # First up-sampling:\n",
    "    x = Conv2DTranspose(filters,\n",
    "                        kernel_size=3,\n",
    "                        padding='same',\n",
    "                        strides=(2, 2),\n",
    "                        activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2DTranspose(filters,\n",
    "                        kernel_size=3,\n",
    "                        padding='same',\n",
    "                        strides=1,\n",
    "                        activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Second up-sampling:\n",
    "    x = Conv2DTranspose(filters,\n",
    "                        kernel_size=3,\n",
    "                        strides=(2, 2),\n",
    "                        padding='valid',\n",
    "                        activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # Ouput 1 channel of gray pixels values between 0 and 1:\n",
    "    x = Conv2D(1, kernel_size=2, padding='valid',\n",
    "               activation='sigmoid')(x)\n",
    "    return Model(decoder_input, x, name='convolutional_decoder')\n",
    "\n",
    "\n",
    "conv_decoder = make_conv_decoder(latent_dim, intermediate_dim, original_dim,\n",
    "                                 spatial_size=7, filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = conv_decoder.predict(np.random.normal(size=(1, latent_dim)))\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new decoder encodes some a priori knowledge on the local dependencies between pixel values in the \"deconv\" architectures. Depending on the randomly initialized weights, the generated images can show some local spatial structure.\n",
    "\n",
    "Try to re-execute the above two cells several times to try to see the kind of local structure that stem from the \"deconv\" architecture it-self for different random initializations of the weights.\n",
    "\n",
    "\n",
    "Again, let's now plug everything to together to get convolutional version of a full VAE model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, img_chns)\n",
    "vae = make_vae(input_shape, conv_encoder, conv_decoder)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train_conv, epochs=15, batch_size=100,\n",
    "        validation_data=(x_test_conv, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save_weights(\"convolutional_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " vae.load_weights(\"convolutional_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = conv_decoder.predict(np.random.normal(size=(1, latent_dim)))\n",
    "plt.imshow(generated.reshape(28, 28), cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D plot of the image classes in the latent space\n",
    "\n",
    "We find again a similar organization of the latent space. Compared to the fully-connected VAE space, the differnt class labels seem slightly better separated. This could be a consequence of the slightly better fit we obtain from the convolutional models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_encoded, _ = conv_encoder.predict(x_test_conv, batch_size=100)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test,\n",
    "            cmap=plt.cm.tab10)\n",
    "cb = plt.colorbar()\n",
    "cb.set_ticks(list(id_to_labels.keys()))\n",
    "cb.set_ticklabels(list(id_to_labels.values()))\n",
    "cb.update_ticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D panel view of samples from the VAE manifold\n",
    "\n",
    "The following linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian to produce values of the latent variables z. This makes it possible to use a square arangement of panels that spans the gaussian prior of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = conv_decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using latent space to train a model on little data\n",
    "\n",
    "- We build a small training set with 10 samples per class\n",
    "- We train a Model directly from the small dataset\n",
    "- We train a Model from the latent space using the small labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x_train = []\n",
    "small_y_train = []\n",
    "\n",
    "num_per_class = 10\n",
    "\n",
    "for c in range(10):\n",
    "    # select 10 random train samples\n",
    "    small_x_train += [x_train_conv[np.random.choice(np.where(y_train==c)[0], size=num_per_class, replace=False)]]\n",
    "    small_y_train += [c] * num_per_class\n",
    "\n",
    "small_x_train = np.vstack(small_x_train)\n",
    "small_y_train = np.array(small_y_train)\n",
    "# create a random permutation of the dataset\n",
    "perm = np.random.permutation(range(small_y_train.shape[0]))\n",
    "small_x_train = small_x_train[perm]\n",
    "small_y_train = small_y_train[perm]\n",
    "\n",
    "small_x_train.shape, small_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(img_rows, img_cols, img_chns))\n",
    "x = Flatten()(inp)\n",
    "x = Dense(10, activation=\"softmax\")(x)\n",
    "mdl = Model(inp, x)\n",
    "mdl.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(small_x_train, small_y_train, \n",
    "        epochs=10,\n",
    "        validation_data=[x_test_encoded, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model on top of the latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x_train_encoded, _ = conv_encoder.predict(small_x_train, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(2,))\n",
    "x = Dense(64, activation=\"relu\")(inp)\n",
    "x = Dense(10, activation=\"softmax\")(x)\n",
    "mdl = Model(inp, x)\n",
    "mdl.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(small_x_train_encoded, small_y_train, \n",
    "        epochs=10,\n",
    "        validation_data=[x_test_encoded, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
