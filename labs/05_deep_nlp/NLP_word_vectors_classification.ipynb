{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification using Neural Networks\n",
    "\n",
    "The goal of this notebook is to learn to use Neural Networks for text classification.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Train a shallow model with learning embeddings\n",
    "- Download pre-trained embeddings from Glove\n",
    "- Use these pre-trained embeddings\n",
    "\n",
    "However keep in mind:\n",
    "- Deep Learning can be better on text classification that simpler ML techniques, but only on very large datasets and well designed/tuned models.\n",
    "- We won't be using the most efficient (in terms of computing) techniques, as Keras is good for prototyping but rather inefficient for training small embedding models on text.\n",
    "- The following projects can replicate similar word embedding models much more efficiently: [word2vec](https://github.com/dav/word2vec) and [gensim's word2vec](https://radimrehurek.com/gensim/models/word2vec.html)   (self-supervised learning only), [fastText](https://github.com/facebookresearch/fastText) (both supervised and self-supervised learning), [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki) (supervised learning).\n",
    "- Plain shallow sparse TF-IDF bigrams features without any embedding and Logistic Regression or Multinomial Naive Bayes is often competitive in small to medium datasets.\n",
    "\n",
    "\n",
    "### 20 Newsgroups Dataset\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\n",
      "Subject: Diamond SS24X, Win 3.1, Mouse cursor\n",
      "Organization: National Library of Medicine\n",
      "Lines: 10\n",
      "\n",
      "\n",
      "Anybody seen mouse cursor distortion running the Diamond 1024x768x256 driver?\n",
      "Sorry, don't know the version of the driver (no indication in the menus) but it's a recently\n",
      "delivered Gateway system.  Am going to try the latest drivers from Diamond BBS but wondered\n",
      "if anyone else had seen this.\n",
      "\n",
      "post or email\n",
      "\n",
      "--Don Lindbergh\n",
      "dabl2@lhc.nlm.nih.gov\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 1000\n",
    "print(newsgroups_train[\"data\"][sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of previous message: comp.os.ms-windows.misc\n"
     ]
    }
   ],
   "source": [
    "target_names = newsgroups_train[\"target_names\"]\n",
    "\n",
    "target_id = newsgroups_train[\"target\"][sample_idx]\n",
    "print(\"Class of previous message:\", target_names[target_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the possible classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text for the (supervised) CBOW model\n",
    "\n",
    "We will implement a simple classification model in Keras. Raw text requires (sometimes a lot of) preprocessing.\n",
    "\n",
    "The following cells uses Keras to preprocess text:\n",
    "- using a tokenizer. You may use different tokenizers (from scikit-learn, NLTK, custom Python function etc.). This converts the texts into sequences of indices representing the `20000` most frequent words\n",
    "- sequences have different lengths, so we pad them (add 0s at the end until the sequence is of length `1000`)\n",
    "- we convert the output classes as 1-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134142 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "# get the raw text data\n",
    "texts_train = newsgroups_train[\"data\"]\n",
    "texts_test = newsgroups_test[\"data\"]\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\n",
    "tokenizer.fit_on_texts(texts_train)\n",
    "sequences = tokenizer.texts_to_sequences(texts_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenized sequences are converted to list of token ids (with an integer code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 4330,\n",
       " 1352,\n",
       " 15,\n",
       " 11234,\n",
       " 38,\n",
       " 250,\n",
       " 29,\n",
       " 42,\n",
       " 298,\n",
       " 9,\n",
       " 17,\n",
       " 95,\n",
       " 78,\n",
       " 91,\n",
       " 4330,\n",
       " 1352,\n",
       " 15,\n",
       " 34,\n",
       " 77,\n",
       " 3,\n",
       " 2967,\n",
       " 610,\n",
       " 1773,\n",
       " 32,\n",
       " 211,\n",
       " 8,\n",
       " 26,\n",
       " 1308,\n",
       " 27,\n",
       " 171,\n",
       " 66,\n",
       " 47,\n",
       " 123,\n",
       " 10112,\n",
       " 63,\n",
       " 16,\n",
       " 17,\n",
       " 298,\n",
       " 8,\n",
       " 708,\n",
       " 1,\n",
       " 86,\n",
       " 263,\n",
       " 11,\n",
       " 26,\n",
       " 4,\n",
       " 36,\n",
       " 1500,\n",
       " 2267,\n",
       " 298,\n",
       " 1163,\n",
       " 2,\n",
       " 18,\n",
       " 14,\n",
       " 1,\n",
       " 1347,\n",
       " 13695,\n",
       " 845,\n",
       " 16114,\n",
       " 11,\n",
       " 26,\n",
       " 337,\n",
       " 4,\n",
       " 1,\n",
       " 4049,\n",
       " 80,\n",
       " 182,\n",
       " 484,\n",
       " 7,\n",
       " 1376,\n",
       " 1,\n",
       " 843,\n",
       " 8321,\n",
       " 26,\n",
       " 1840,\n",
       " 14,\n",
       " 1,\n",
       " 818,\n",
       " 3,\n",
       " 1,\n",
       " 726,\n",
       " 17,\n",
       " 9,\n",
       " 44,\n",
       " 8,\n",
       " 88,\n",
       " 27,\n",
       " 171,\n",
       " 39,\n",
       " 4,\n",
       " 833,\n",
       " 273,\n",
       " 1080,\n",
       " 2918,\n",
       " 198,\n",
       " 3,\n",
       " 2809,\n",
       " 153,\n",
       " 17,\n",
       " 298,\n",
       " 9,\n",
       " 239,\n",
       " 629,\n",
       " 25,\n",
       " 808,\n",
       " 357,\n",
       " 13,\n",
       " 21,\n",
       " 16,\n",
       " 17,\n",
       " 386,\n",
       " 298,\n",
       " 181,\n",
       " 112,\n",
       " 188,\n",
       " 206,\n",
       " 1503,\n",
       " 1343,\n",
       " 2,\n",
       " 13,\n",
       " 35,\n",
       " 58,\n",
       " 7972]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer object stores a mapping (vocabulary) from word strings to token ids that can be inverted to reconstruct the original message (without formatting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 134142)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer.word_index), len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_word = dict((i, w) for w, i in tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from wam umd edu where's my thing subject what car is this nntp posting host wam umd edu organization university of maryland college park lines 15 i was wondering if anyone out there could enlighten me on this car i saw the other day it was a 2 door sports car looked to be from the late 60s early 70s it was called a the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can a model name engine specs years of production where this car is made history or whatever info you have on this looking car please e mail thanks il brought to you by your neighborhood\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([index_to_word[i] for i in sequences[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the tokenized sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length: 302.5\n",
      "max length: 15365\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [len(s) for s in sequences]\n",
    "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
    "print(\"max length: %d\" % max(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAFkCAYAAADynzv4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZLUqv8fRjwCpOpRCPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80545a7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(seq_lens, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom on the distribution of regular sized posts. The vast majority of the posts have less than 1000 symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8033c96358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([l for l in seq_lens if l < 3000], bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's truncate and pad all the sequences to 1000 symbols to build the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (11314, 1000)\n",
      "Shape of data test tensor: (7532, 1000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "\n",
    "# pad sequences with 0s\n",
    "x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of data test tensor:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (11314, 20)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = newsgroups_train[\"target\"]\n",
    "y_test = newsgroups_test[\"target\"]\n",
    "\n",
    "y_train = to_categorical(np.asarray(y_train))\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple supervised CBOW model in Keras\n",
    "\n",
    "The following computes a very simple model, as described in [fastText](https://github.com/facebookresearch/fastText):\n",
    "\n",
    "<img src=\"images/fasttext.svg\" style=\"width: 600px;\" />\n",
    "\n",
    "- Build an embedding layer mapping each word to a vector representation\n",
    "- Compute the vector representation of all words in each sequence and average them\n",
    "- Add a dense layer to output 20 classes (+ softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "N_CLASSES = len(target_names)\n",
    "\n",
    "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "average = GlobalAveragePooling1D()(embedded_sequences)\n",
    "predictions = Dense(N_CLASSES, activation='softmax')(average)\n",
    "\n",
    "model = Model(sequence_input, predictions)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.9873 - acc: 0.0849 - val_loss: 2.9786 - val_acc: 0.1661\n",
      "Epoch 2/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.9630 - acc: 0.1545 - val_loss: 2.9537 - val_acc: 0.1793\n",
      "Epoch 3/10\n",
      "10182/10182 [==============================] - 7s - loss: 2.9297 - acc: 0.1673 - val_loss: 2.9164 - val_acc: 0.1820\n",
      "Epoch 4/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.8880 - acc: 0.2081 - val_loss: 2.8731 - val_acc: 0.2412\n",
      "Epoch 5/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.8420 - acc: 0.2526 - val_loss: 2.8274 - val_acc: 0.2783\n",
      "Epoch 6/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.7928 - acc: 0.3041 - val_loss: 2.7787 - val_acc: 0.3224\n",
      "Epoch 7/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.7376 - acc: 0.3712 - val_loss: 2.7234 - val_acc: 0.3710\n",
      "Epoch 8/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.6747 - acc: 0.4211 - val_loss: 2.6618 - val_acc: 0.4028\n",
      "Epoch 9/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.6053 - acc: 0.4576 - val_loss: 2.5948 - val_acc: 0.4382\n",
      "Epoch 10/10\n",
      "10182/10182 [==============================] - 6s - loss: 2.5305 - acc: 0.5107 - val_loss: 2.5225 - val_acc: 0.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80545ac320>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1,\n",
    "          nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    " - compute model accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/accuracy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building more complex models\n",
    "\n",
    "**Exercise**\n",
    "- From the previous template, build more complex models using:\n",
    "  - 1d convolution and 1d maxpooling. Note that you will still need a GloabalAveragePooling or Flatten after the convolutions\n",
    "  - Recurrent neural networks through LSTM (you will need to reduce sequence length before)\n",
    "  \n",
    "  \n",
    "<img src=\"images/unrolled_rnn_one_output_2.svg\" style=\"width: 600px;\" />\n",
    "\n",
    "**Bonus**\n",
    "- You may try different architectures with:\n",
    "  - more intermediate layers, combination of dense, conv, recurrent\n",
    "  - different recurrent (GRU, RNN)\n",
    "  - bidirectional LSTMs\n",
    "\n",
    "Note: The goal is to build working models rather than getting better test accuracy. To achieve much better results, we'd need more computation time and data quantity. Build your model, and verify that they converge to OK results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, LSTM, GRU\n",
    "from keras.layers import MaxPooling1D, GlobalAveragePooling1D \n",
    "from keras.models import Model\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "N_CLASSES = len(target_names)\n",
    "\n",
    "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# TODO\n",
    "\n",
    "model = Model(sequence_input, predictions)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/conv1d.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1,\n",
    "          nb_epoch=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained embeddings\n",
    "\n",
    "The file `glove100K.100d.txt` is an extract of [Glove](http://nlp.stanford.edu/projects/glove/) Vectors, that were trained on english Wikipedia 2014 + Gigaword 5 (6B tokens).\n",
    "\n",
    "We extracted the `100 000` most frequent words. They have a dimension of `100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "embeddings_vectors = []\n",
    "f = open('glove100K.100d.txt', 'rb')\n",
    "\n",
    "word_idx = 0\n",
    "for line in f:\n",
    "    values = line.decode('utf-8').split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = word_idx\n",
    "    embeddings_vectors.append(vector)\n",
    "    word_idx = word_idx + 1\n",
    "f.close()\n",
    "\n",
    "inv_index = {v: k for k, v in embeddings_index.items()}\n",
    "print(\"found %d different words in the file\" % word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stack all embeddings in a large numpy array\n",
    "glove_embeddings = np.vstack(embeddings_vectors)\n",
    "glove_norms = np.linalg.norm(glove_embeddings, axis=-1, keepdims=True)\n",
    "glove_embeddings_normed = glove_embeddings / glove_norms\n",
    "print(glove_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_emb(word):\n",
    "    idx = embeddings_index.get(word)\n",
    "    if idx is None:\n",
    "        return None\n",
    "    else:\n",
    "        return glove_embeddings[idx]\n",
    "\n",
    "    \n",
    "def get_normed_emb(word):\n",
    "    idx = embeddings_index.get(word)\n",
    "    if idx is None:\n",
    "        return None\n",
    "    else:\n",
    "        return glove_embeddings_normed[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_emb(\"computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding most similar words\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "Build a function to find most similar words, given a word as query:\n",
    "- lookup the vector for the query word in the Glove index;\n",
    "- compute the cosine similarity between a word embedding and all other words;\n",
    "- display the top 10 most similar words.\n",
    "\n",
    "**Bonus**\n",
    "\n",
    "Change your function so that it takes multiple words as input (by averaging them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/most_similar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_similar(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_similar(\"pitt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_similar(\"jolie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the future better than tarot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(get_normed_emb('aniston'), get_normed_emb('pitt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(get_normed_emb('jolie'), get_normed_emb('pitt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_similar(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bonus: yangtze is a chinese river\n",
    "most_similar([\"river\", \"chinese\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying vectors with  t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "word_emb_tsne = TSNE(perplexity=30).fit_transform(glove_embeddings_normed[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(40, 40))\n",
    "axis = plt.gca()\n",
    "np.set_printoptions(suppress=True)\n",
    "plt.scatter(word_emb_tsne[:, 0], word_emb_tsne[:, 1], marker=\".\", s=1)\n",
    "\n",
    "for idx in range(1000):\n",
    "    plt.annotate(inv_index[idx],\n",
    "                 xy=(word_emb_tsne[idx, 0], word_emb_tsne[idx, 1]),\n",
    "                 xytext=(0, 0), textcoords='offset points')\n",
    "plt.savefig(\"tsne.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained embeddings in our model\n",
    "\n",
    "We want to use these pre-trained embeddings for transfer learning. This process is rather similar than transfer learning in image recognition: the features learnt on words might help us bootstrap the learning process, and increase performance if we don't have enough training data.\n",
    "- We initialize embedding matrix from the model with Glove embeddings:\n",
    " - take all words from our 20 Newgroup vocabulary (`MAX_NB_WORDS = 20000`), and look up their Glove embedding \n",
    " - place the Glove embedding at the corresponding index in the matrix\n",
    " - if the word is not in the Glove vocabulary, we only place zeros in the matrix\n",
    "- We may fix these embeddings or fine-tune them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# prepare embedding matrix\n",
    "nb_words_in_matrix = 0\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = get_emb(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        nb_words_in_matrix = nb_words_in_matrix + 1\n",
    "        \n",
    "print(\"added %d words in the embedding matrix\" % nb_words_in_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a layer with pre-trained embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_embedding_layer = Embedding(\n",
    "    MAX_NB_WORDS, EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_SEQUENCE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A model with pre-trained Embeddings\n",
    "\n",
    "Average word embeddings pre-trained with Glove / Word2Vec usually works suprisingly well. However, when averaging more than `10-15` words, the resulting vector becomes too noisy and classification performance is degraded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = pretrained_embedding_layer(sequence_input)\n",
    "average = GlobalAveragePooling1D()(embedded_sequences)\n",
    "predictions = Dense(N_CLASSES, activation='softmax')(average)\n",
    "\n",
    "model = Model(sequence_input, predictions)\n",
    "\n",
    "# We don't want to fine-tune embeddings\n",
    "model.layers[1].trainable=False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1,\n",
    "          nb_epoch=10, batch_size=128, )\n",
    "\n",
    "# Note, on this type of task, this technique will \n",
    "# degrade results as we train much less parameters\n",
    "# and we average a large number pre-trained embeddings.\n",
    "# You will notice much less overfitting then!\n",
    "# Using convolutions / LSTM will help\n",
    "# It is also advisable to treat seperately pre-trained\n",
    "# embeddings and words out of vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reality check\n",
    "\n",
    "On small/medium datasets, simpler classification methods usually perform better, and are much more efficient to compute. Here are two resources to go further:\n",
    "- Naive Bayes approach, using scikit-learn http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "- Alec Radford (OpenAI) gave a very interesting presentation, showing that you need a VERY large dataset to have real gains from GRU/LSTM in text classification https://www.slideshare.net/odsc/alec-radfordodsc-presentation\n",
    "\n",
    "However, when looking at features, one can see that classification using simple methods isn't very robust, and won't generalize well to slightly different domains (e.g. forum posts => emails)\n",
    "\n",
    "Note: Implementation in Keras for text is very slow due to python overhead and lack of hashing techniques. The fastText implementation https://github.com/facebookresearch/fasttext is much, much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Going further\n",
    "\n",
    "- Compare pre-trained embeddings vs specifically trained embeddings\n",
    "- Train your own wordvectors in any language using [gensim's word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "- Check [Keras Examples](https://github.com/fchollet/keras/tree/master/examples) on `imdb` sentiment analysis\n",
    "- Install fastText (Linux or macOS only, use the Linux VM if under Windows) and give it a try on the classification example in its repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
