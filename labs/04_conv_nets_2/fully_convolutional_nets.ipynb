{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Neural Networks\n",
    "\n",
    "Objectives:\n",
    "- Load a CNN model pre-trained on ImageNet\n",
    "- Transform the network into a Fully Convolutional Network \n",
    "- Apply the network perform weak segmentation on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet50\n",
    "# We use include_top = False for now,\n",
    "# as we'll import output Dense Layer later\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(include_top=False)\n",
    "\n",
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res5c = base_model.layers[-2]\n",
    "type(res5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res5c.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_pool = base_model.layers[-1]\n",
    "type(avg_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_pool.pool_size, avg_pool.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_pool.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully convolutional ResNet\n",
    "\n",
    "- Out of the `res5c` residual block, the resnet outputs a tensor of shape $H \\times W \\times 2048$. \n",
    "- For the default ImageNet input, $224 \\times 224$, the output size is $7 \\times 7 \\times 2048$\n",
    "- After this bloc, the ResNet uses an average pooling `AveragePooling2D(pool_size=(7, 7))` with `(7, 7)` strides which divides by 7 the width and height\n",
    "\n",
    "#### Regular ResNet layers \n",
    "\n",
    "The regular ResNet head after the base model is as follows: \n",
    "```py\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1000)(x)\n",
    "x = Softmax()(x)\n",
    "```\n",
    "\n",
    "Here is the full definition of the model: https://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py\n",
    "\n",
    "#### Our Version\n",
    "\n",
    "- To keep spatial information as much as possible, we will remove the average pooling.\n",
    "- We want to retrieve the labels information, which is stored in the Dense layer. We will load these weights afterwards\n",
    "- We will change the Dense Layer to a Convolution layer to keep spatial information, to output a $H \\times W \\times 1000$.\n",
    "- We want to apply a softmax only on the last dimension\n",
    "\n",
    "#### A custom Softmax\n",
    "\n",
    "We build the following Custom Layer to apply a softmax only to the last dimension of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "# A custom layer in Keras must implement the four following functions:\n",
    "class SoftmaxMap(Layer):\n",
    "    # Init function\n",
    "    def __init__(self, axis=-1,**kwargs):\n",
    "        self.axis=axis\n",
    "        super(SoftmaxMap, self).__init__(**kwargs)\n",
    "\n",
    "    # There's no parameters, so we don't need this one\n",
    "    def build(self,input_shape):\n",
    "        pass\n",
    "\n",
    "    # This is the layer we're interested in. \n",
    "    # Very similar to the regular softmax\n",
    "    def call(self, x, mask=None):\n",
    "        e = K.exp(x - K.max(x, axis=self.axis, keepdims=True))\n",
    "        s = K.sum(e, axis=self.axis, keepdims=True)\n",
    "        return e / s\n",
    "\n",
    "    # The output shape is the same as the input shape\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise **\n",
    "- What is the shape of the convolution kernel we want to apply to replace the Dense ?\n",
    "- Build the fully convolutional model as described above.\n",
    "- You may use `base_model.layers` to find which layer to remove\n",
    "- You may use the Keras `Convolution2D(output_channels, filter, filter)` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.models import Model\n",
    "\n",
    "input = base_model.layers[0].input\n",
    "# TODO\n",
    "output = input\n",
    "\n",
    "fully_conv_ResNet = Model(input = input, output = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/fully_conv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dense weights\n",
    "\n",
    "- we provide the weights and bias of the last Dense layer of ResNet50 in file `weights_dense.h5`\n",
    "- our last layer is now a convolutional layer instead of Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('weights_dense.h5','r')\n",
    "w = h5f['w'][:]\n",
    "b = h5f['b'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_layer = fully_conv_ResNet.layers[-2]\n",
    "\n",
    "print(\"loaded weight shape\", w.shape)\n",
    "print(\"conv last layer weights shape\", last_layer.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape the weights\n",
    "w_reshaped = w.reshape((1,1,2048,1000))\n",
    "\n",
    "# set the conv layer weights\n",
    "last_layer.set_weights([w_reshaped, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A forward pass\n",
    "\n",
    "- We define the following function to test our new network. \n",
    "- It resizes the input to a given size, then uses `model.predict` to compute the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def forward_pass_resize(img_path, img_size):\n",
    "    img_raw = imread(img_path)\n",
    "    print(\"img shape before resizing: \"+ str(img_raw.shape))\n",
    "    img = imresize(img_raw, size=img_size).astype(\"float32\")\n",
    "    img = preprocess_input(img[np.newaxis])\n",
    "    print(\"img batch size shape before forward pass:\", img.shape)\n",
    "    z = fully_conv_ResNet.predict(img)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = forward_pass_resize(\"dog.jpg\", (800,600))\n",
    "print(\"output shape\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding dog-related classes\n",
    "ImageNet uses an ontology of concepts, from which classes are derived. A synset corresponds to a node in the ontology.\n",
    "\n",
    "For example species of dogs are children nodes of the synset `dog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper file for importing synsets from imagenet\n",
    "import imagenet_tool\n",
    "synset = \"n02084071\" # synset corresponding to dogs\n",
    "ids = imagenet_tool.synset_to_dfs_ids(synset)\n",
    "print(\"all dog classes ids\", ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised heatmap of the class \"dog\"\n",
    "\n",
    "The following function builds a heatmap from a forward pass. It sums the representation for all ids corresponding to a synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_heatmap(z, synset):\n",
    "    ids = imagenet_tool.synset_to_dfs_ids(synset)\n",
    "    ids = np.array([id_ for id_ in ids if id_ is not None])\n",
    "    x = z[0,:,:,ids].sum(axis=0)\n",
    "    print(\"size of heatmap: \" + str(x.shape))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_img_and_heatmap(img_path, heatmap):\n",
    "    dog = imread(img_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(dog)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(heatmap, interpolation='nearest', cmap=\"viridis\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- What is the size of the heatmap compared to the input image?\n",
    "- Build 3 dog heatmaps from `\"dog.jpg\"`, with the following sizes:\n",
    "  - `(400, 640)`\n",
    "  - `(800, 1280)`\n",
    "  - `(1600, 2560)`\n",
    "- What do you observe? \n",
    "\n",
    "You may plot a heatmap using the above function `display_img_and_heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dog synset\n",
    "s = \"n02084071\"\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/build_heatmaps.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_img_and_heatmap(\"dog.jpg\", heatmap_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the 3 heatmaps\n",
    "By combining the heatmaps at different scales, we obtain a much better information about the location of the dog.\n",
    "\n",
    "**Bonus**\n",
    "- Combine the three heatmap by resizing them to a similar shape, and averaging them\n",
    "- A geometric norm will work better than standard average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/geom_avg.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
