<!DOCTYPE html>
<html>
  <head>
    <title>Deep Learning Lectures</title>
    <meta charset="utf-8">
    <style>
     .left-column {
       width: 50%;
       float: left;
     }
     .right-column {
       width: 50%;
       float: right;
     }
     .grey { color: #bbbbbb; }
      </style>
    <link rel="stylesheet" type="text/css" href="slides.css">
  </head>
  <body>
      <textarea id="source">
class: center, middle

# Class imbalance and Metric Learning

Charles Ollion - Olivier Grisel

.affiliations[
  ![Heuritech](images/heuritech-logo.png)
  ![Inria](images/inria-logo.png)
  ![UPS](images/Logo_Master_Datascience.png)
]

---
## Classic Deep Learning data setup

Classification with 1 class per sample
2-1000 classes ; 1000 samples per class

--

What if I have multiple classes per sample?

--

What if I have unbalanced or noisy labels?

--

what if I have 1M classes and 10 samples / class?

---
# Outline

### Multi-labeling and Sampling strategies

--

### Metric Learning and siamese networks

--

### Dealing with weak and noisy labels

---
class: middle, center

Multi-labeling and Sampling strategies

---

# From Classification to multilabel

### todo

training with binary labels

---
class: middle, center

Triplet loss and Siamese networks

---
## Goal: learn systems with few examples

ex: Face Recognition/Verification

--

- Recognition: Given a face, classify among K possible persons
- Verification: verify that two faces belongs to the same person

todo add image face

--

A verification system = similarity measure. If it's really good, useful for recognition
---
## Metric learning

d( img1, img2 ) = degree of difference between images.
We want d result to be low in case of the same faces.
We use tau T as a threshold for d:
If d( img1, img2 ) <= T Then the faces are the same.
Similarity function helps us solving the one shot learning. Also its robust to new inputs.
Siamese Network
We will implement the similarity function using a type of NNs called Siamease Network in which we can pass multiple inputs to the two or more networks with the same architecture and parameters.
Siamese network architecture are as the following:

We make 2 identical conv nets which encodes an input image into a vector. In the above image the vector shape is (128, )
The loss function will be d(x1, x2) = || f(x1) - f(x2) ||2
If X1, X2 are the same person, we want d to be low. If they are different persons, we want d to be high.
[Taigman et. al., 2014. DeepFace closing the gap to human level performance]
Triplet Loss
Triplet Loss is one of the loss functions we can use to solve the similarity distance in a Siamese network.
Our learning objective in the triplet loss function is to get the distance between an Anchor image and a positive or a negative image.
Positive means same person, while negative means different person.
The triplet name came from that we are comparing an anchor A with a positive P and a negative N image.
Formally we want:
Positive distance to be less than negative distance
||f(A) - f(P)||2 <= ||f(A) - f(N)||2
Then
||f(A) - f(P)||2 - ||f(A) - f(N)||2 <= 0
To make sure the NN won't get an output of zeros easily:
||f(A) - f(P)||2 - ||f(A) - f(N)||2 <= -alpha
Alpha is a small number. Sometimes its called the margin.
Then
||f(A) - f(P)||2 - ||f(A) - f(N)||2 + alpha <= 0
Final Loss function:
Given 3 images (A, P, N)
L(A, P, N) = max (||f(A) - f(P)||2 - ||f(A) - f(N)||2 + alpha , 0)
J = Sum((A[i], P[i], N[i]) , i) for all triplets of images.
You need multiple images of the same person in your dataset. Then get some triplets out of your dataset. Dataset should be big enough.
Choosing the triplets A, P, N:
During training if A, P, N are chosen randomly (Subjet to A and P are the same and A and N aren't the same) then one of the problems this constrain is easily satisfied
d(A, P) + alpha <= d (A, N)
So the NN wont learn much
What we want to do is choose triplets that are hard to train on.
So for all the triplets we want this to be satisfied:
d(A, P) + alpha <= d (A, N)
This can be achieved by for example same poses!
Find more at the paper.
Details are in this paper [Schroff et al.,2015, FaceNet: A unified embedding for face recognition and clustering]
Commercial recognition systems are trained on a large datasets like 10/100 million images.
There are a lot of pretrained models and parameters online for face recognition.
Face Verification and Binary Classification
Triplet loss is one way to learn the parameters of a conv net for face recognition there's another way to learn these parameters as a straight binary classification problem.
Learning the similarity function another way:

The final layer is a sigmoid layer.
Y' = wi * Sigmoid ( f(x(i)) - f(x(j)) ) + b where the subtraction is the Manhattan distance between f(x(i)) and f(x(j))
Some other similarities can be Euclidean and Ki square similarity.
The NN here is Siamese means the top and bottom convs has the same parameters.
The paper for this work: [Taigman et. al., 2014. DeepFace closing the gap to human level performance]
A good performance/deployment trick:
Pre-compute all the images that you are using as a comparison to the vector f(x(j))
When a new image that needs to be compared, get its vector f(x(i)) then put it with all the pre computed vectors and pass it to the sigmoid function.
This version works quite as well as the triplet loss function.
Available implementations for face recognition using deep learning includes:
Openface
FaceNet
DeepFace


---
class: middle, center

# Lab 1: Room C48-C49 in 15min!

    </textarea>
    <style TYPE="text/css">
      code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
      }
      });
      MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
		     all[i].SourceElement().parentNode.className += ' has-jax';
		     }
		     });
		     </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../remark.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true
      });
    </script>
  </body>
</html>
